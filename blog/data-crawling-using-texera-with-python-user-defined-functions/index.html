<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=fonts/vendor/jost/jost-v4-latin-500.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><link rel=stylesheet href=/main.3dba5d6040a4881d63e49604f8058c2bd1bd4e0b1f90277da3335388da407cb3cdb0ddde89c7815107e4f7fcfa6aded5fdf6b5c7cc32ec54bd85e740300c3148.css integrity="sha512-PbpdYECkiB1j5JYE+AWMK9G9TgsfkCd9ozNTiNpAfLPNsN3eiceBUQfk9/z6at7V/fa1x8wy7FS9hedAMAwxSA==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>Data Crawling Using Texera with Python User-Defined Functions - Texera</title><meta name=description content="Crawling is a common yet important task to collect data from the Web. However, developing a good crawling pipeline is notoriously challenging due to the following reasons:
  The content and format of the Web pages can be quite unpredictable. Many &amp;ldquo;edge cases&amp;rdquo; need to be covered by the crawler and the parser. Moreover, these edge cases can happen after the pipeline has been running for a long time. This could cause the parser to extract wrong information, or even crash the program."><link rel=canonical href=/blog/data-crawling-using-texera-with-python-user-defined-functions/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="Data Crawling Using Texera with Python User-Defined Functions"><meta property="og:description" content="Crawling is a common yet important task to collect data from the Web. However, developing a good crawling pipeline is notoriously challenging due to the following reasons:
  The content and format of the Web pages can be quite unpredictable. Many &ldquo;edge cases&rdquo; need to be covered by the crawler and the parser. Moreover, these edge cases can happen after the pipeline has been running for a long time. This could cause the parser to extract wrong information, or even crash the program."><meta property="og:url" content="/blog/data-crawling-using-texera-with-python-user-defined-functions/"><meta property="og:site_name" content="Texera"><meta property="article:published_time" content="2022-08-30T09:19:42+01:00"><meta property="article:modified_time" content="2022-08-30T09:19:42+01:00"><meta property="og:image" content="doks.png"><meta property="og:image:alt" content="Texera"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content><meta name=twitter:creator content><meta name=twitter:title content="Data Crawling Using Texera with Python User-Defined Functions"><meta name=twitter:description content><meta name=twitter:image content="doks.png"><meta name=twitter:image:alt content="Data Crawling Using Texera with Python User-Defined Functions"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"/#/schema/organization/1","name":"Texera","url":"/","sameAs":["https://github.com/texera/texera"],"logo":{"@type":"ImageObject","@id":"/#/schema/image/1","url":"/logo-doks.png","width":512,"height":512,"caption":"Texera"},"image":{"@id":"/#/schema/image/1"}},{"@type":"WebSite","@id":"/#/schema/website/1","url":"/","name":"Texera","description":"Texera is a system to support collaborative, ML-centric data analytics as a cloud-based service using GUI-based workflows. It supports scalable computation with a parallel backend engine, and enables advanced AI\/ML techniques.","publisher":{"@id":"/#/schema/organization/1"}},{"@type":"WebPage","@id":"/blog/data-crawling-using-texera-with-python-user-defined-functions/","url":"/blog/data-crawling-using-texera-with-python-user-defined-functions/","name":"Data Crawling Using Texera with Python User-Defined Functions","description":"","isPartOf":{"@id":"/#/schema/website/1"},"about":{"@id":"/#/schema/organization/1"},"datePublished":"2022-08-30T09:19:42CET","dateModified":"2022-08-30T09:19:42CET","breadcrumb":{"@id":"/blog/data-crawling-using-texera-with-python-user-defined-functions/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"/blog/data-crawling-using-texera-with-python-user-defined-functions/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["/blog/data-crawling-using-texera-with-python-user-defined-functions/"]}]},{"@type":"BreadcrumbList","@id":"/blog/data-crawling-using-texera-with-python-user-defined-functions/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"","url":"","name":"Home"}},{"@type":"ListItem","position":3,"item":{"@type":"WebPage","@id":"/blog/","url":"/blog/","name":"Blog"}},{"@type":"ListItem","position":4,"item":{"@id":"/blog/data-crawling-using-texera-with-python-user-defined-functions/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Article","@id":"/#/schema/article/1","headline":"Data Crawling Using Texera with Python User-Defined Functions","description":"","isPartOf":{"@id":"/blog/data-crawling-using-texera-with-python-user-defined-functions/"},"mainEntityOfPage":{"@id":"/blog/data-crawling-using-texera-with-python-user-defined-functions/"},"datePublished":"2022-08-30T09:19:42CET","dateModified":"2022-08-30T09:19:42CET","author":{"@id":"/#/schema/person/2"},"publisher":{"@id":"/#/schema/organization/1"},"image":{"@id":"/blog/data-crawling-using-texera-with-python-user-defined-functions/#/schema/image/2"}}]},{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"/#/schema/person/2","name":"Texera Team","sameAs":[]}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"/blog/data-crawling-using-texera-with-python-user-defined-functions/#/schema/image/2","url":"doks.png","contentUrl":"doks.png","caption":"Data Crawling Using Texera with Python User-Defined Functions"}]}]}</script><meta name=theme-color content="#fff"><link rel=apple-touch-icon sizes=180x180 href=apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=site.webmanifest></head><body class="blog single"><div class=header-bar></div><header class="navbar navbar-expand-md navbar-light doks-navbar"><nav class="container-fluid flex-wrap flex-md-nowrap" aria-label="Main navigation"><a class="navbar-brand p-0 me-auto" href=/ aria-label=Texera>Texera</a>
<button class="btn btn-menu d-block d-md-none order-5" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-end border-0 py-md-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-md-none"></div><div class="offcanvas-header d-md-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=/>Texera</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body px-4"><h3 class="h6 text-uppercase mb-3 d-md-none">Main</h3><ul class="nav flex-column flex-md-row ms-md-n3"><li class=nav-item><a class="nav-link ps-0 py-1 active" href=/blog/>Blog</a></li></ul><hr class="text-black-50 my-4 d-md-none"><h3 class="h6 text-uppercase mb-3 d-md-none">Socials</h3><ul class="nav flex-column flex-md-row ms-md-auto me-md-n5 pe-md-2"><li class=nav-item><a class="nav-link ps-0 py-1" href=/https:/github.com/h-enk/doks><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><small class="ms-2 d-md-none">GitHub</small></a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/https:/twitter.com/getdoks><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-twitter"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg><small class="ms-2 d-md-none">Twitter</small></a></li></ul></div></div></nav></header><div class="wrap container-fluid" role=document><div class=content><div class="row justify-content-center"><div class="col-md-12 col-lg-10 col-xl-8"><article><div class=blog-header><h1>Data Crawling Using Texera with Python User-Defined Functions</h1><p><small>Posted August 30, 2022
by
<a class="stretched-link position-relative" href=/contributors/zuozhi-wang/>Zuozhi Wang</a>
from
<a class="stretched-link position-relative" href=/affiliations/computer-science-uc-irvine/>Computer Science, UC Irvine</a>
&nbsp;&dash;&nbsp;
<strong>7&nbsp;min read</strong></small><p></div><p class=lead>In this blog, we share the experience of using Texera to crawl, clean, and analyze Web data.</p><p>Crawling is a common yet important task to collect data from the Web. However, developing a good crawling pipeline is notoriously challenging due to the following reasons:</p><ol><li><p>The content and format of the Web pages can be quite unpredictable. Many &ldquo;edge cases&rdquo; need to be covered by the crawler and the parser. Moreover, these edge cases can happen after the pipeline has been running for a long time. This could cause the parser to extract wrong information, or even crash the program.</p></li><li><p>Many Web sites have rate-limiting or anti-crawling mechanisms. If not done carefully, the crawler might be blocked. One might run a crawler pipeline for a long time, then find out that the crawler is blocked. In such a case, the crawler needs to reduce the request rate on-the-fly, or even temporarily pause the execution.</p></li></ol><p>In this post, we share our experience on setting up a crawling pipeline on Texera, primarily using its Python User-Defined Function (UDF) support. Moreover, we show how Texera&rsquo;s dynamic execution control features, such as pausing, resuming, dynamically updating code on the fly, can help solve the above issues, and make it easier to develop and run such a pipeline.</p><h3 id=task-overview>Task Overview <a href=#task-overview class=anchor aria-hidden=true>#</a></h3><p>We have many warehouse addresses in California, as shown in the sample dataset below. We would like to find the size of the property on each address. We&rsquo;ll fetch the information from <a href=https://www.loopnet.com/>loopnet.com</a>, an online marketplace providing commercial property listings.</p><table class=table-sm><thead><tr><th style=text-align:left>address</th></tr></thead><tbody><tr><td style=text-align:left>1230 N Tustin Ave, Anaheim, CA 92807</td></tr><tr><td style=text-align:left>3201 W Mission Rd, Alhambra, California, 91803</td></tr><tr><td style=text-align:left>1000 N Edward Ct, Anaheim, California, 92806</td></tr><tr><td style=text-align:left>1045 S East St, Anaheim, California, 92805</td></tr><tr><td style=text-align:left>2801 W Mission Rd, Alhambra, California, 91803</td></tr><tr><td style=text-align:left>&mldr;&mldr;</td></tr></tbody></table><p>To fetch the information, we can follow the following procedures:</p><ol><li><p>Search an address on Google followed by the keyword <code>loopnet</code>. Usually, the first Google search result points to the property record page that we are looking for.
<img src=google_search_address.png width=550></p></li><li><p>Follow the URL to visit <a href=https://www.loopnet.com/>loopnet.com</a>. Navigating to the <code>PROPERTY DETAIL</code> section of the page, we find the size of the property in <code>TOTAL SQ FT</code>.
<img src=loopnet_detail.png width=1000></p></li></ol><p>To repeat the same procedure for all the addresses, we programmatically implement a crawler and a parser using Texera&rsquo;s Python user-defined functions.
We also use the following Python libraries:</p><ul><li><a href=https://requests.readthedocs.io/en/latest/><code>requests</code></a> to make HTTP requests.</li><li><a href=https://beautiful-soup-4.readthedocs.io/en/latest/><code>BeautifulSoup</code></a> to parse HTML pages and extract information.</li></ul><h3 id=texera-workflow-overview>Texera Workflow Overview <a href=#texera-workflow-overview class=anchor aria-hidden=true>#</a></h3><p>The following screenshot shows the Texera workflow we have constructed.</p><img src=workflow_overview.png width=700><ul><li>The first operator, <code>Read Address</code>, reads a CSV file containing the warehouse addresses we need to crawl.</li><li>The second operator, <code>Search Google</code>, sends an HTTP request to Google and fetches the result HTML page. It then parses the HTML page to find the first search result and the URL of the loopnet page. The code for this operator can be found below.</li></ul><details><summary>Python UDF code for operator "Search Google"</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ProcessTupleOperator</span><span class=p>(</span><span class=n>UDFOperatorV2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@overrides</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>process_tuple</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tuple_</span><span class=p>:</span> <span class=n>Tuple</span><span class=p>,</span> <span class=n>port</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Iterator</span><span class=p>[</span><span class=n>Optional</span><span class=p>[</span><span class=n>TupleLike</span><span class=p>]]:</span>
</span></span><span class=line><span class=cl>        <span class=n>address</span> <span class=o>=</span> <span class=n>tuple_</span><span class=p>[</span><span class=s1>&#39;address&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># fetch the google search result HTML page</span>
</span></span><span class=line><span class=cl>        <span class=n>googleQuery</span> <span class=o>=</span> <span class=s2>&#34;http://google.com/search?q=&#34;</span> <span class=o>+</span> <span class=n>urllib</span><span class=o>.</span><span class=n>parse</span><span class=o>.</span><span class=n>quote</span><span class=p>(</span><span class=n>address</span><span class=o>+</span> <span class=s2>&#34; loopnet&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>googlePage</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>googleQuery</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># parse the HTML page to extract URL from the top search result</span>
</span></span><span class=line><span class=cl>        <span class=n>soup</span> <span class=o>=</span> <span class=n>BeautifulSoup</span><span class=p>(</span><span class=n>googlePage</span><span class=o>.</span><span class=n>text</span><span class=p>,</span> <span class=s1>&#39;html.parser&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loopnetUrlRaw</span> <span class=o>=</span> <span class=p>[</span><span class=n>r</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=n>soup</span><span class=o>.</span><span class=n>find_all</span><span class=p>(</span><span class=s1>&#39;a&#39;</span><span class=p>,</span> <span class=n>href</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> <span class=k>if</span> <span class=s2>&#34;loopnet.com&#34;</span> <span class=ow>in</span> <span class=n>r</span><span class=p>[</span><span class=s1>&#39;href&#39;</span><span class=p>]][</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;href&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>loopnetUrl</span> <span class=o>=</span> <span class=n>loopnetUrlRaw</span><span class=p>[</span><span class=n>loopnetUrlRaw</span><span class=o>.</span><span class=n>find</span><span class=p>(</span><span class=s2>&#34;http&#34;</span><span class=p>):</span> <span class=n>loopnetUrlRaw</span><span class=o>.</span><span class=n>rfind</span><span class=p>(</span><span class=s2>&#34;/&#34;</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>        <span class=n>tuple_</span><span class=p>[</span><span class=s1>&#39;loopnet_url&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>loopnetUrl</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># avoid making crawling requests too frequently</span>
</span></span><span class=line><span class=cl>        <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>yield</span> <span class=n>tuple_</span>
</span></span></code></pre></div></details><ul><li>The third operator takes the loopnet URL and fetches the property listing page from loopnet.com. It parses the HTML page to locate the <code>PROPERTY DETAIL</code> section, and extracts the size information.</li></ul><details><summary>Python UDF code for operator "Fetch Property Info"</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ProcessTupleOperator</span><span class=p>(</span><span class=n>UDFOperatorV2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@overrides</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>process_tuple</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tuple_</span><span class=p>:</span> <span class=n>Tuple</span><span class=p>,</span> <span class=n>port</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Iterator</span><span class=p>[</span><span class=n>Optional</span><span class=p>[</span><span class=n>TupleLike</span><span class=p>]]:</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>loopnetUrl</span> <span class=o>=</span> <span class=n>tuple_</span><span class=p>[</span><span class=s1>&#39;loopnet_url&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># fetch loopnet HTML page</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>loopnetPageHtml</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>loopnetUrl</span><span class=p>,</span> <span class=n>headers</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;User-Agent&#34;</span><span class=p>:</span> <span class=s2>&#34;Mozilla/5.0 (platform; rv:geckoversion) Gecko/geckotrail Firefox/firefoxversion&#34;</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=n>loopnetPage</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>loopnetPageHtml</span><span class=o>.</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># parse the PROPERTY DETAIL section of the HTML page</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>soup</span> <span class=o>=</span> <span class=n>BeautifulSoup</span><span class=p>(</span><span class=n>loopnetPage</span><span class=p>,</span> <span class=s1>&#39;html.parser&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>assessments</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>soup</span><span class=o>.</span><span class=n>find_all</span><span class=p>(</span><span class=n>class_</span><span class=o>=</span><span class=s2>&#34;assessment-key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>kv</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>node</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>assessments</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>key</span> <span class=o>=</span> <span class=n>node</span><span class=o>.</span><span class=n>findChildren</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>value</span> <span class=o>=</span> <span class=n>node</span><span class=o>.</span><span class=n>parent</span><span class=o>.</span><span class=n>findChildren</span><span class=p>()[</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>kv</span><span class=p>[</span><span class=n>key</span><span class=p>]</span> <span class=o>=</span> <span class=n>value</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>tuple_</span><span class=p>[</span><span class=s2>&#34;area&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>kv</span><span class=p>[</span><span class=s2>&#34;TOTAL SQ FT&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>yield</span> <span class=n>tuple_</span>
</span></span></code></pre></div></details><p>Next, we run this workflow and check the results. Texera starts running the pipeline progressively and displays the results.
<img src=run_workflow.gif></p><h2 id=handling-edge-cases>Handling Edge Cases <a href=#handling-edge-cases class=anchor aria-hidden=true>#</a></h2><p>As discussed in the beginning of this blog, the crawler and the parser often run into edge cases where the Web page&rsquo;s format or content changes. This is no exception for the warehouse address crawling task. After running the pipeline for a while, the job runs into an exception, as shown in the following animated gif. The error message shows <code>line 64, in process_tuple KeyError: 'TOTAL SQ FT'</code>. This indicates that the <code>TOTAL SQ FT</code> information is not extracted.</p><img src=run_workflow_exception.gif><p>In Texera, an exception raised by the Python UDF will not crash the program. Instead, Texera gracefully catches the exception, reports the error to the user, and keeps the program in a paused state. We can interact with the Python UDF operator and inspect the tuple that causes this program to crash, and any internal state of the UDF operator.</p><img src=inspect.gif><p>We can easily find the address that causes this issue and visit its loopnet web page. This address is a corner case where the property is not listed on the Web site.</p><img src=not_advertised.png width=600>
<img src=not_advertised_info.png width=600><p>We can see that both the page layout and the content are different from regular listings. Therefore, we need to update the parser code to extract the property size from <code>Building Size</code>, instead of <code>TOTAL SQ FT</code>.</p><p>We can take advantage of Texera&rsquo;s functionality to change the parser on-the-fly, without restarting the crawling pipeline from scratch. The following gif shows the process, and the updated code can be seen below.</p><img src=fix_bug.gif>
<details><summary>Updated code for operator "Fetch Property Info" after fixing error</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ProcessTupleOperator</span><span class=p>(</span><span class=n>UDFOperatorV2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@overrides</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>process_tuple</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tuple_</span><span class=p>:</span> <span class=n>Tuple</span><span class=p>,</span> <span class=n>port</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Iterator</span><span class=p>[</span><span class=n>Optional</span><span class=p>[</span><span class=n>TupleLike</span><span class=p>]]:</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>loopnetUrl</span> <span class=o>=</span> <span class=n>tuple_</span><span class=p>[</span><span class=s1>&#39;loopnet_url&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># fetch loopnet HTML page</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>loopnetPageHtml</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>loopnetUrl</span><span class=p>,</span> <span class=n>headers</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;User-Agent&#34;</span><span class=p>:</span> <span class=s2>&#34;Mozilla/5.0 (platform; rv:geckoversion) Gecko/geckotrail Firefox/firefoxversion&#34;</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=n>loopnetPage</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>loopnetPageHtml</span><span class=o>.</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># check if the property is advertised on loopnet</span>
</span></span><span class=line><span class=cl>        <span class=n>notAdvertised</span> <span class=o>=</span> <span class=s2>&#34;no longer advertised on LoopNet.com&#34;</span> <span class=ow>in</span> <span class=n>loopnetPage</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>notAdvertised</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># parse the data of a property that is not advertised</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>propertyData</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>soup</span><span class=o>.</span><span class=n>find</span><span class=p>(</span><span class=n>class_</span><span class=o>=</span><span class=s2>&#34;property-data&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>find_all</span><span class=p>(</span><span class=s2>&#34;td&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>propertyData</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>propertyData</span>
</span></span><span class=line><span class=cl>            <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>propertyData</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>while</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>propertyData</span><span class=p>)</span> <span class=o>-</span> <span class=mi>2</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>k</span> <span class=o>=</span> <span class=n>propertyData</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                    <span class=n>v</span> <span class=o>=</span> <span class=n>propertyData</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=n>k</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=nb>len</span><span class=p>(</span><span class=n>k</span><span class=p>)</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=bp>self</span><span class=o>.</span><span class=n>kv</span><span class=p>[</span><span class=n>k</span><span class=p>]</span> <span class=o>=</span> <span class=n>v</span>
</span></span><span class=line><span class=cl>                    <span class=n>i</span> <span class=o>+=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>tuple_</span><span class=p>[</span><span class=s2>&#34;area&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>kv</span><span class=p>[</span><span class=s2>&#34;Building Size&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># parse the PROPERTY DETAIL section of the HTML page</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>soup</span> <span class=o>=</span> <span class=n>BeautifulSoup</span><span class=p>(</span><span class=n>loopnetPage</span><span class=p>,</span> <span class=s1>&#39;html.parser&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>assessments</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>soup</span><span class=o>.</span><span class=n>find_all</span><span class=p>(</span><span class=n>class_</span><span class=o>=</span><span class=s2>&#34;assessment-key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>kv</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>node</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>assessments</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>key</span> <span class=o>=</span> <span class=n>node</span><span class=o>.</span><span class=n>findChildren</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=n>value</span> <span class=o>=</span> <span class=n>node</span><span class=o>.</span><span class=n>parent</span><span class=o>.</span><span class=n>findChildren</span><span class=p>()[</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>kv</span><span class=p>[</span><span class=n>key</span><span class=p>]</span> <span class=o>=</span> <span class=n>value</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>tuple_</span><span class=p>[</span><span class=s2>&#34;area&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>kv</span><span class=p>[</span><span class=s2>&#34;TOTAL SQ FT&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>yield</span> <span class=n>tuple_</span>
</span></span></code></pre></div></details><p>During the running of the crawling pipeline, there have been many instances of finding and fixing corner cases, such as:</p><ul><li>There are different phrases to indicate whether a property is advertised on loopnet. Some use &ldquo;no longer advertised on LoopNet.com&rdquo;, and others use &ldquo;no longer <em>being</em> advertised on LoopNet.com&rdquo;.</li><li>Different property types use different keys to show property size. Some use &ldquo;TOTAL SQ FT&rdquo;, some use &ldquo;Building Size&rdquo;, and others use &ldquo;Total Rentable Area&rdquo;.</li></ul><p>Using Texera, we are immediately notified when such edge cases happen, and we can fix the issues on the fly.</p><h3 id=dynamically-adjusting-request-rate>Dynamically Adjusting Request Rate <a href=#dynamically-adjusting-request-rate class=anchor aria-hidden=true>#</a></h3><p>In the crawler implementation, we initially set a low rate of two requests per second for the crawler to avoid being blocked. After running the pipeline for a while, we notice that the crawler does not reach the limit of the crawled Web sites. Thus we increase the request rate to five requests per second to make the pipeline run faster.</p><img src=change_rate.gif><p>Similarly, when the crawler starts to get an invalid response from the Web site, it is a sign of the request rate being too high. In this case, we can again reduce the request rate.</p><h3 id=summary>Summary <a href=#summary class=anchor aria-hidden=true>#</a></h3><p>In this blog, we share the experience of using Texera to build a crawling pipeline to collect Web data. Texera&rsquo;s powerful ability to control the pipeline execution allows us to monitor issues during runtime and fix the issues on the fly.</p><h4 id=acknowledgements>Acknowledgements <a href=#acknowledgements class=anchor aria-hidden=true>#</a></h4><p>Thanks to Chen Li for his help on this blog.</p></article></div></div></div></div><footer class="footer text-muted"><div class=container-fluid><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item></li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline></ul></div></div></div></footer><script src=/js/bootstrap.min.0a0106334435d4110713bfaff4acaf02533b0c56d44412a74e9518db07672ddb7e099a9c7517bc9cb529e2ddd4ae2e438b40b720288900d5e74fb6d8928d9097.js integrity="sha512-CgEGM0Q11BEHE7+v9KyvAlM7DFbURBKnTpUY2wdnLdt+CZqcdRe8nLUp4t3Uri5Di0C3ICiJANXnT7bYko2Qlw==" crossorigin=anonymous defer></script>
<script src=/js/highlight.min.576fdb91cfd303e8fc247b90cc678e7d3304777de963077ad78eb70811a476919edaebf1d2843057250ec536b7ed1bd40f4e48f06e7cfc9c569dcf7581afd08b.js integrity="sha512-V2/bkc/TA+j8JHuQzGeOfTMEd33pYwd61463CBGkdpGe2uvx0oQwVyUOxTa37RvUD05I8G58/JxWnc91ga/Qiw==" crossorigin=anonymous defer></script>
<script src=/main.min.0382ba481d9dbcd1dd4c82111208ebf5d7eda2fce9378b0b14257d7f117c79f8ae01591f6ad0a99917b4e1624d8ace90de964e2431ab237000161ebd3c3dad63.js integrity="sha512-A4K6SB2dvNHdTIIREgjr9dftovzpN4sLFCV9fxF8efiuAVkfatCpmRe04WJNis6Q3pZOJDGrI3AAFh69PD2tYw==" crossorigin=anonymous defer></script></body></html>