<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Zuozhi Wang on</title><link>/contributors/zuozhi-wang/</link><description>Recent content in Zuozhi Wang on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Tue, 30 Aug 2022 09:19:42 +0100</lastBuildDate><atom:link href="/contributors/zuozhi-wang/index.xml" rel="self" type="application/rss+xml"/><item><title>Data Crawling Using Texera with Python User-Defined Functions</title><link>/blog/data-crawling-using-texera-with-python-user-defined-functions/</link><pubDate>Tue, 30 Aug 2022 09:19:42 +0100</pubDate><guid>/blog/data-crawling-using-texera-with-python-user-defined-functions/</guid><description>Crawling is a common yet important task to collect data from the Web. However, developing a good crawling pipeline is notoriously challenging due to the following reasons:
The content and format of the Web pages can be quite unpredictable. Many &amp;ldquo;edge cases&amp;rdquo; need to be covered by the crawler and the parser. Moreover, these edge cases can happen after the pipeline has been running for a long time. This could cause the parser to extract wrong information, or even crash the program.</description></item></channel></rss>